# Research: Human Intent vs AI Throughput

<!--
metadata:
  id: foundations-human-ai-intent-2025-12-26
  title: Human Intent vs AI Throughput Research
  date: 2025-12-26
  author: research-librarian
  status: approved
  topic: foundations
  also_relevant: []
  keywords: [human-ai-collaboration, intent-maintenance, cognitive-load, throughput, academic-research]
  consensus: medium
  epistemic_standard: survey
  sources_count: 6
  supersedes: null
  related: [foundations-classical-roots-2025-12-28]
  approved_by: human
  approved_date: 2025-12-30
-->

## Executive Summary

- Academic research validates the Praxis problem statement: AI amplifies throughput, not coherence
- The "comfort-growth paradox" (Riva): AI's ease fosters intellectual stagnation
- Shared representations act as guardrails for human-AI collaboration (Ding et al.)
- The "dual black box problem" (Lu): Converting implicit human intent to auditable systems
- Praxis is ahead of academics in having a working operational system

## Consensus Rating

**Medium**: Based on recent academic papers (2025), which haven't yet been widely cited. Core findings align with practitioner experience.

## Body

### The Praxis Position

> "A practical, operational system for knowledge workers."

AI amplifies throughput, not coherence. The bottleneck moved from production to intent-maintenance. Praxis makes human intent durable enough to survive AI's speed.

### Deep Thinkers in This Space

#### 1. Giuseppe Riva — "The Comfort-Growth Paradox" (2025)

**Paper:** _The Architecture of Cognitive Amplification: Enhanced Cognitive Scaffolding as a Resolution to the Comfort-Growth Paradox in Human-AI Cognitive Integration_

**Citation:** arXiv:2507.19483 [cs.HC]
**URL:** https://arxiv.org/abs/2507.19483

**Key findings:**

- **The paradox:** AI's user-friendly nature fosters intellectual stagnation by minimizing cognitive friction necessary for development
- **The trap:** AI aligns with user preferences and provides frictionless assistance → induces _cognitive complacency_ rather than growth
- **His solution:** "Enhanced Cognitive Scaffolding" — reconceptualize AI from convenient assistant to dynamic mentor with:
  - Progressive autonomy (AI support fades as competence increases)
  - Adaptive personalization
  - Cognitive load optimization

**Relevance to Praxis:** Riva frames the problem academically but doesn't provide operational structure. Praxis's lifecycle stages are a concrete implementation of his "progressive autonomy" concept.

#### 2. Ding et al. — "The Diagram is like Guardrails" (2025)

**Paper:** _"The Diagram is like Guardrails": Structuring GenAI-assisted Hypotheses Exploration with an Interactive Shared Representation_

**Citation:** arXiv:2503.16791 [cs.HC]
**URL:** https://arxiv.org/abs/2503.16791
**Authors:** Zijian Ding, Michelle Brachman, Joel Chan, Werner Geyer

**Key finding:** Shared representations (diagrams) act as guardrails for human-AI collaboration:

- Facilitate structured workflows
- Provide comprehensive overviews
- Enable efficient backtracking
- Reduce cognitive load while maintaining human agency

**Relevance to Praxis:** Validates the SOD/formalization artifact approach. The diagram = shared state that prevents drift. `praxis.yaml` + canonical docs serve the same function.

#### 3. Yiming Lu — "Dual Black Box Problem" (2025)

**Paper:** _Deconstructing the Dual Black Box: A Plug-and-Play Cognitive Framework for Human-AI Collaborative Enhancement and Its Implications for AI Governance_

**Citation:** arXiv:2512.08740 [cs.AI]
**URL:** https://arxiv.org/abs/2512.08740

**Key insight:** Identifies the fundamental divide:

- Human "cognitive black box" (implicit intuition)
- AI "computational black box" (untrustworthy decision-making)

Proposes converting both into **auditable, composable "functional white-box" systems** through structured meta-interaction.

**Relevance to Praxis:** The three-layer model (Opinions → Governance → Execution) is essentially this. Praxis makes human intent explicit enough to govern AI output.

### The Gap Praxis Fills

The academic work focuses on:

- Identifying the paradox (Riva)
- Proving shared representations help (Ding)
- Theoretical frameworks (Lu)

**What's missing:** A practical, operational system for knowledge workers. Praxis is that system.

## Reusable Artifacts

### Academic Concept → Praxis Implementation

| Academic Concept       | Praxis Implementation                  |
| ---------------------- | -------------------------------------- |
| Comfort-growth paradox | Formalize as friction point            |
| Cognitive scaffolding  | Lifecycle stages                       |
| Shared representation  | praxis.yaml, SOD, canonical docs       |
| Progressive autonomy   | Discovery → Refinement iteration modes |
| Auditable white-box    | Domain + Stage + Privacy → Behavior    |

### Search Terms That Surface This Space

**Direct framing:**
- "AI productivity paradox intent maintenance"
- "cognitive overhead AI collaboration"
- "human coherence bottleneck generative AI"

**Academic/research:**
- "attention allocation human-AI teaming"
- "sensemaking overload AI assistants"
- "agency preservation AI augmentation"

**Practitioner:**
- "AI pair programming context drift"
- "LLM workflow governance"
- "prompt engineering decision fatigue"

### Additional Papers (Not Deep-Dived)

From arXiv search "human AI collaboration cognitive load" (35 results):

- **arXiv:2512.18239** — Emergent Learner Agency in Implicit Human-AI Collaboration
- **arXiv:2512.11979** — Designing The Internet of Agents: A Framework for Trustworthy Human-Agent Interaction
- **arXiv:2510.03369** — TriQuest: AI Copilot-Powered Platform for Interdisciplinary Curriculum Design
- **arXiv:2505.06947** — The Wisdom of Agent Crowds: Human-AI Interaction Innovation Framework
- **arXiv:2505.01192** — Exploring the Impact of Explainable AI and Cognitive Capabilities on Users' Decisions
- **arXiv:2502.09787** — TableTalk: Scaffolding Spreadsheet Development with a Language Agent (reduced cognitive load 2.3x)

## Sources

1. Riva, G. (2025). The Architecture of Cognitive Amplification. arXiv:2507.19483
2. Ding, Z. et al. (2025). The Diagram is like Guardrails. arXiv:2503.16791
3. Lu, Y. (2025). Deconstructing the Dual Black Box. arXiv:2512.08740
4. Various (2025). arXiv search "human AI collaboration cognitive load"
5. Various (2025). arXiv search "AI productivity paradox"
6. Various (2025). arXiv search "cognitive scaffolding AI"

---

_Migrated from research/foundations/research-human-ai-intent-maintenance.md_
_Approved: 2025-12-30_
